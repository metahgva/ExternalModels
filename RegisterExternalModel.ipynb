{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea60d27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-Av68uqrW1ACcue2UlbRDvxSj0huAq', 'object': 'chat.completion', 'created': 1738171672, 'model': 'gpt-3.5-turbo-0125', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'Why did the rabbit bring a ladder to the party? \\n\\nBecause he heard the drinks were on the house!', 'tool_calls': None}, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 13, 'completion_tokens': 23, 'total_tokens': 36}}\n"
     ]
    }
   ],
   "source": [
    "# This is using an LLM Gateway endpoint \n",
    "\n",
    "from mlflow.deployments import get_deploy_client\n",
    "import os\n",
    "\n",
    "client = get_deploy_client(os.environ['DOMINO_MLFLOW_DEPLOYMENTS'])\n",
    "\n",
    "response = client.predict(\n",
    "    endpoint=\"chat-gpt35t-se\",\n",
    "    inputs={\"messages\": [{\"role\": \"user\", \"content\": \"Tell me a joke about rabbits\"}]}\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "228cc749",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'llmgateway_chatgpt_endpoint'.\n",
      "2025/01/29 17:30:48 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: llmgateway_chatgpt_endpoint, version 1\n",
      "Created version '1' of model 'llmgateway_chatgpt_endpoint'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run useful-colt-136 at: http://127.0.0.1:8768/#/experiments/1197/runs/6e34f7f9462b455a821e0cd7710bfe83\n",
      "üß™ View experiment at: http://127.0.0.1:8768/#/experiments/1197\n",
      "Model registered as version: 1\n"
     ]
    }
   ],
   "source": [
    "# Register the LLM Gateway invoke in the Model Registry \n",
    "\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "from mlflow.deployments import get_deploy_client\n",
    "import os\n",
    "\n",
    "\n",
    "class ChatGPTWrapper(mlflow.pyfunc.PythonModel):\n",
    "    def predict(self, context, model_input):\n",
    "        client = get_deploy_client(os.environ['DOMINO_MLFLOW_DEPLOYMENTS'])\n",
    "        response = client.predict(\n",
    "            endpoint=\"chat-gpt35t-se\",\n",
    "            inputs={\"messages\": [{\"role\": \"user\", \"content\": model_input}]}\n",
    "        )\n",
    "        return response\n",
    "\n",
    "# Log the model\n",
    "with mlflow.start_run():\n",
    "    model_path = \"llmgateway_chatgpt_endpoint\"\n",
    "    mlflow.pyfunc.save_model(path=model_path, python_model=ChatGPTWrapper())\n",
    "    mlflow.log_artifact(model_path)\n",
    "\n",
    "    # Register the model\n",
    "    model_uri = f\"runs:/{mlflow.active_run().info.run_id}/{model_path}\"\n",
    "    model_version = mlflow.register_model(model_uri, \"llmgateway_chatgpt_endpoint\")\n",
    "\n",
    "print(f\"Model registered as version: {model_version.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7260ea3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/11 08:54:44 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: S3_ExternalModel, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model version registered: <RegisteredModel: aliases={}, creation_timestamp=1736585684712, description='', last_updated_timestamp=1736585684712, latest_versions=[], name='S3_ExternalModel', tags={'mlflow.domino.dataset_info': '6782311fba6ede24a00ebd04-6782311fba6ede24a00ebd03',\n",
      " 'mlflow.domino.environment_id': '6597567f09b1d67423f20b08',\n",
      " 'mlflow.domino.environment_revision_id': '677edd235a8b340810246187',\n",
      " 'mlflow.domino.hardware_tier': 'small-k8s',\n",
      " 'mlflow.domino.project_id': '6782311cba6ede24a00ebcfe',\n",
      " 'mlflow.domino.project_name': 'ExternalModelsGovernance',\n",
      " 'mlflow.domino.provenance_checkpoint_id': '67823150694b370819279742',\n",
      " 'mlflow.domino.run_id': '6782313d4e300d5189a80fd7',\n",
      " 'mlflow.domino.run_number': '1',\n",
      " 'mlflow.domino.user': 'ahmet_gyger',\n",
      " 'mlflow.domino.user_id': '654d51dac89cb93b0f7a9b1f',\n",
      " 'mlflow.source.git.branch': 'main',\n",
      " 'mlflow.source.git.commit': '7af15da5efdb0c12b223698c5e761b108dffc1b4',\n",
      " 'mlflow.source.type': 'NOTEBOOK',\n",
      " 'mlflow.user': 'ahmet_gyger'}>\n"
     ]
    }
   ],
   "source": [
    "# Example of creating an empty model shell in the model registry\n",
    "# The external model URI is not showing up in our Model Card\n",
    "\n",
    "import mlflow\n",
    "\n",
    "# Initialize MLFlow client\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "# External model URI (for example, on AWS S3 or another location)\n",
    "external_model_uri = \"s3://my-bucket/my-model\"\n",
    "\n",
    "# Register the model with a name, linking to the external model URI\n",
    "model_details = client.create_registered_model(name=\"S3_ExternalModel\")\n",
    "\n",
    "# Create a new version of the registered model pointing to the external URI\n",
    "client.create_model_version(name=\"S3_ExternalModel\", source=external_model_uri, run_id=None)\n",
    "\n",
    "print(f\"Model version registered: {model_details}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51da2bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/14 12:57:51 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Open_AIWhisper, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model version registered: <RegisteredModel: aliases={}, creation_timestamp=1728910671892, description='', last_updated_timestamp=1728910671892, latest_versions=[], name='Open_AIWhisper', tags={'mlflow.domino.dataset_info': '67037c6567037a343ab8b95a-67037c6567037a343ab8b959',\n",
      " 'mlflow.domino.environment_id': '66d0bc8f8c8ab661269a8f42',\n",
      " 'mlflow.domino.environment_revision_id': '66d0bc8f8c8ab661269a8f44',\n",
      " 'mlflow.domino.hardware_tier': 'small-k8s',\n",
      " 'mlflow.domino.project_id': '67037c6167037a343ab8b953',\n",
      " 'mlflow.domino.project_name': 'ExternalModel',\n",
      " 'mlflow.domino.provenance_checkpoint_id': '670d14a611d05f656b656af9',\n",
      " 'mlflow.domino.run_id': '670d136f11d05f656b656ae2',\n",
      " 'mlflow.domino.run_number': '4',\n",
      " 'mlflow.domino.user': 'integration-test',\n",
      " 'mlflow.domino.user_id': '66d0bc00a14e7c9cc1e3a3e2',\n",
      " 'mlflow.source.git.branch': 'main',\n",
      " 'mlflow.source.git.commit': '5d188a759ee91588b051e0aaecabe7f964e38f20',\n",
      " 'mlflow.source.type': 'NOTEBOOK',\n",
      " 'mlflow.user': 'integration-test'}>\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Initialize MLFlow client\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "# External model URI \n",
    "external_model_uri = \"https://huggingface.co/openai/whisper-large-v3-turbo/tree/main\"\n",
    "\n",
    "# Register the model with a name, linking to the external model URI\n",
    "model_details = client.create_registered_model(name=\"Open_AIWhisper\")\n",
    "\n",
    "# Create a new version of the registered model pointing to the external URI\n",
    "client.create_model_version(name=\"Open_AIWhisper\", source=external_model_uri, run_id=None)\n",
    "\n",
    "print(f\"Model version registered: {model_details}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e76bd47c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RestException",
     "evalue": "INVALID_PARAMETER_VALUE: Missing value for required parameter 'source'. See the API docs for more information about request parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRestException\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m model_details \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mcreate_registered_model(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShell1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Create a new version of the registered model pointing to the external URI\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_model_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mShell1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel version registered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_details\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/tracking/client.py:2986\u001b[0m, in \u001b[0;36mMlflowClient.create_model_version\u001b[0;34m(self, name, source, run_id, tags, run_link, description, await_creation_for)\u001b[0m\n\u001b[1;32m   2908\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_model_version\u001b[39m(\n\u001b[1;32m   2909\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2910\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2916\u001b[0m     await_creation_for: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m DEFAULT_AWAIT_MAX_SLEEP_SECONDS,\n\u001b[1;32m   2917\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ModelVersion:\n\u001b[1;32m   2918\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2919\u001b[0m \u001b[38;5;124;03m    Create a new model version from given source.\u001b[39;00m\n\u001b[1;32m   2920\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[38;5;124;03m        Stage: None\u001b[39;00m\n\u001b[1;32m   2985\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2986\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_model_version\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2987\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2988\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2989\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2990\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2991\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_link\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_link\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2992\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2993\u001b[0m \u001b[43m        \u001b[49m\u001b[43mawait_creation_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mawait_creation_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2994\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/tracking/client.py:2897\u001b[0m, in \u001b[0;36mMlflowClient._create_model_version\u001b[0;34m(self, name, source, run_id, tags, run_link, description, await_creation_for, local_model_path)\u001b[0m\n\u001b[1;32m   2889\u001b[0m     \u001b[38;5;66;03m# NOTE: we can't easily delete the target temp location due to the async nature\u001b[39;00m\n\u001b[1;32m   2890\u001b[0m     \u001b[38;5;66;03m# of the model version creation - printing to let the user know.\u001b[39;00m\n\u001b[1;32m   2891\u001b[0m     eprint(\n\u001b[1;32m   2892\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== Source model files were copied to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_source\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2893\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the model registry workspace. You may want to delete the files once the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2894\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m model version is in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mREADY\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m status. You can also find this location in the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2895\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `source` field of the created model version. ===\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2896\u001b[0m     )\n\u001b[0;32m-> 2897\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_registry_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_model_version\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2899\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2900\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2901\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2902\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_link\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_link\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2903\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2904\u001b[0m \u001b[43m    \u001b[49m\u001b[43mawait_creation_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mawait_creation_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2905\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_model_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2906\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/tracking/_model_registry/client.py:215\u001b[0m, in \u001b[0;36mModelRegistryClient.create_model_version\u001b[0;34m(self, name, source, run_id, tags, run_link, description, await_creation_for, local_model_path)\u001b[0m\n\u001b[1;32m    213\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m _get_arg_names(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore\u001b[38;5;241m.\u001b[39mcreate_model_version)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal_model_path\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m arg_names:\n\u001b[0;32m--> 215\u001b[0m     mv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_model_version\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_link\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_model_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# Fall back to calling create_model_version without\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;66;03m# local_model_path since old model registry store implementations may not\u001b[39;00m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# support the local_model_path argument.\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     mv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore\u001b[38;5;241m.\u001b[39mcreate_model_version(name, source, run_id, tags, run_link, description)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/store/model_registry/rest_store.py:267\u001b[0m, in \u001b[0;36mRestStore.create_model_version\u001b[0;34m(self, name, source, run_id, tags, run_link, description, local_model_path)\u001b[0m\n\u001b[1;32m    256\u001b[0m proto_tags \u001b[38;5;241m=\u001b[39m [tag\u001b[38;5;241m.\u001b[39mto_proto() \u001b[38;5;28;01mfor\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m tags \u001b[38;5;129;01mor\u001b[39;00m []]\n\u001b[1;32m    257\u001b[0m req_body \u001b[38;5;241m=\u001b[39m message_to_json(\n\u001b[1;32m    258\u001b[0m     CreateModelVersion(\n\u001b[1;32m    259\u001b[0m         name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    265\u001b[0m     )\n\u001b[1;32m    266\u001b[0m )\n\u001b[0;32m--> 267\u001b[0m response_proto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCreateModelVersion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq_body\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ModelVersion\u001b[38;5;241m.\u001b[39mfrom_proto(response_proto\u001b[38;5;241m.\u001b[39mmodel_version)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/store/model_registry/base_rest_store.py:44\u001b[0m, in \u001b[0;36mBaseRestStore._call_endpoint\u001b[0;34m(self, api, json_body, call_all_endpoints, extra_headers)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m     endpoint, method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_endpoint_from_method(api)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_endpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_host_creds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_proto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_headers\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/utils/rest_utils.py:290\u001b[0m, in \u001b[0;36mcall_endpoint\u001b[0;34m(host_creds, endpoint, method, json_body, response_proto, extra_headers)\u001b[0m\n\u001b[1;32m    288\u001b[0m     call_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m json_body\n\u001b[1;32m    289\u001b[0m     response \u001b[38;5;241m=\u001b[39m http_request(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcall_kwargs)\n\u001b[0;32m--> 290\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mverify_rest_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m js_dict \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m    292\u001b[0m parse_dict(js_dict\u001b[38;5;241m=\u001b[39mjs_dict, message\u001b[38;5;241m=\u001b[39mresponse_proto)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/utils/rest_utils.py:173\u001b[0m, in \u001b[0;36mverify_rest_response\u001b[0;34m(response, endpoint)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _can_parse_as_json_object(response\u001b[38;5;241m.\u001b[39mtext):\n\u001b[0;32m--> 173\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m RestException(json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mtext))\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m         base_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    176\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI request to endpoint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    177\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed with error code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != 200\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    178\u001b[0m         )\n",
      "\u001b[0;31mRestException\u001b[0m: INVALID_PARAMETER_VALUE: Missing value for required parameter 'source'. See the API docs for more information about request parameters."
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Initialize MLFlow client\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "\n",
    "# Register the model with a name, linking to the external model URI\n",
    "model_details = client.create_registered_model(name=\"Shell1\")\n",
    "\n",
    "# Create a new version of the registered model pointing to the external URI\n",
    "client.create_model_version(name=\"Shell1\", source='', run_id=None)\n",
    "\n",
    "print(f\"Model version registered: {model_details}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "430c5182",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'EmptyModel'.\n",
      "2025/01/11 09:04:24 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: EmptyModel, version 1\n",
      "Created version '1' of model 'EmptyModel'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run bright-shrew-450 at: http://127.0.0.1:8768/#/experiments/1197/runs/5a043c2a84be48e3832d4cd211a6d32d\n",
      "üß™ View experiment at: http://127.0.0.1:8768/#/experiments/1197\n",
      "Empty model registered successfully.\n"
     ]
    }
   ],
   "source": [
    "# Model Registry with a text file attached to it. \n",
    "# Information about the external model could be documented on that file\n",
    "\n",
    "import os\n",
    "import mlflow\n",
    "\n",
    "# Directory where the empty model file will be created\n",
    "model_dir = \"empty_model\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Path to the empty model file\n",
    "empty_model_file_path = os.path.join(model_dir, \"empty_model.txt\")\n",
    "\n",
    "# Create an empty file\n",
    "with open(empty_model_file_path, 'w') as f:\n",
    "    f.write(\"\")  # Write nothing to create an empty file\n",
    "\n",
    "# Start an MLFlow run\n",
    "with mlflow.start_run() as run:\n",
    "    # Log the empty model file as an artifact\n",
    "    mlflow.log_artifact(empty_model_file_path, artifact_path=\"model\")\n",
    "\n",
    "    # Register the model\n",
    "    model_uri = f\"runs:/{run.info.run_id}/model\"\n",
    "    mlflow.register_model(model_uri=model_uri, name=\"EmptyModel\")\n",
    "\n",
    "print(\"Empty model registered successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "386e229c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Create ChatGPT endpoint (chat completions)\n",
    "#\n",
    "\n",
    "import mlflow.pyfunc\n",
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import mlflow.pyfunc\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the endpoint details\n",
    "endpoint_url = \"https://api.openai.com/v1/chat/completions\"\n",
    "api_key = \"sk-proj-\"#\"<your_openai_api_key>\"\n",
    "\n",
    "\n",
    "class ChatGPTModelWrapper(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self, endpoint_url, api_key):\n",
    "        self.endpoint_url = endpoint_url\n",
    "        self.api_key = api_key\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        # Convert input to a list of strings (assumes DataFrame or Series input)\n",
    "        if isinstance(model_input, pd.DataFrame):\n",
    "            messages = model_input.iloc[:, 0].tolist()\n",
    "        elif isinstance(model_input, pd.Series):\n",
    "            messages = model_input.tolist()\n",
    "        elif isinstance(model_input, list):\n",
    "            messages = model_input\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported input format for model_input\")\n",
    "\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        }\n",
    "        payload = {\n",
    "            \"model\": \"gpt-4\",\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": message} for message in messages],\n",
    "        }\n",
    "        response = requests.post(self.endpoint_url, headers=headers, json=payload)\n",
    "        \n",
    "        # Raise an error for bad HTTP responses\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Extract the API response\n",
    "        return [choice[\"message\"][\"content\"] for choice in response.json()[\"choices\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0fe65edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid naming conflict in the model path name \n",
    "# Get the current time\n",
    "current_time = datetime.now()\n",
    "formatted_time = current_time.strftime(\"%d_%H_%M\")\n",
    "\n",
    "# Save the wrapped model to a local directory\n",
    "model_path = f\"chatgpt_model_{formatted_time}\"\n",
    "mlflow.pyfunc.save_model(\n",
    "    path=model_path,\n",
    "    python_model=ChatGPTModelWrapper(endpoint_url, api_key),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b19138d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'ChatGPT_Model_28_21_51' already exists. Creating a new version of this model...\n",
      "2025/01/28 21:58:49 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: ChatGPT_Model_28_21_51, version 3\n",
      "Created version '3' of model 'ChatGPT_Model_28_21_51'.\n",
      "/tmp/ipykernel_231/206864616.py:68: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  model_version = client.get_latest_versions(name=registered_name, stages=[\"None\"])[0].version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run enthused-dog-687 at: http://127.0.0.1:8768/#/experiments/1197/runs/385b2b21e634461983e8f8a175c6b1ef\n",
      "üß™ View experiment at: http://127.0.0.1:8768/#/experiments/1197\n"
     ]
    }
   ],
   "source": [
    "# Example metrics and tags\n",
    "\n",
    "metrics = {\n",
    "    \"accuracy\": 0.94,\n",
    "    \"bleu_score\": 0.85,\n",
    "    \"rouge_l\": 0.72,\n",
    "    \"perplexity\": 15.2,\n",
    "    \"inference_time_per_token\": 0.004,\n",
    "    \"win_rate_against_baseline\": 0.78,\n",
    "    \"toxicity_rate\": 0.02,\n",
    "    \"hallucination_rate\": 0.08,\n",
    "    \"engagement_score\": 4.7\n",
    "}\n",
    "\n",
    "parameters = {\n",
    "    \"model_size\": \"40B\",\n",
    "    \"batch_size\": 64,\n",
    "    \"learning_rate\": 5e-5,\n",
    "    \"max_tokens\": 1024,\n",
    "    \"training_data_size\": \"570GB\",\n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \"dropout_rate\": 0.1\n",
    "}\n",
    "\n",
    "tags = {\n",
    "    \"model_type\": \"ChatGPT\",\n",
    "    \"developer\": \"Ahmet Gyger\",\n",
    "    \"use_case\": \"Text Summarization\",\n",
    "    \"version\": \"v3.0\"\n",
    "}\n",
    "\n",
    "# Log and register the model\n",
    "with mlflow.start_run() as run:\n",
    "    registered_name=f\"ChatGPT_Model_{formatted_time}\"\n",
    "    \n",
    "    # Log metrics\n",
    "    for key, value in metrics.items():\n",
    "        mlflow.log_metric(key, value)\n",
    "        \n",
    "    # Log parameters\n",
    "    for key, value in parameters.items():\n",
    "        mlflow.log_param(key, value)\n",
    "\n",
    "    \n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path=model_path,\n",
    "        python_model=ChatGPTModelWrapper(endpoint_url, api_key),\n",
    "        registered_model_name=registered_name,\n",
    "        input_example=pd.DataFrame([\"Hello, how are you?\"], columns=[\"prompt\"])\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Use MLflow Client to set registered model tags\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    client.set_registered_model_tag(\n",
    "        name=registered_name,\n",
    "        key=\"use_case\",\n",
    "        value=\"ChatGPT automated predictions\"\n",
    "    )\n",
    "    client.set_registered_model_tag(\n",
    "        name=registered_name,\n",
    "        key=\"priority\",\n",
    "        value=\"high\"\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Get the latest model version\n",
    "    model_version = client.get_latest_versions(name=registered_name, stages=[\"None\"])[0].version\n",
    "\n",
    "    # Set tags for the specific model version\n",
    "    for key, value in tags.items():\n",
    "        client.set_model_version_tag(\n",
    "            name=registered_name,  \n",
    "            version=model_version,\n",
    "            key=key,  \n",
    "            value=value  \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "902bfd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/mlflow/store/artifact/utils/models.py:31: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  latest = client.get_latest_versions(name, None if stage is None else [stage])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f00d41ed2a97467093423fd66fae20f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"As an artificial intelligence, I don't have feelings, but I'm here and ready to help you. How can I assist you today?\"]\n"
     ]
    }
   ],
   "source": [
    "import mlflow.pyfunc\n",
    "import pandas as pd\n",
    "\n",
    "# Load the registered model\n",
    "model = mlflow.pyfunc.load_model(\"models:/ChatGPT_Model/latest\")\n",
    "\n",
    "# Test predictions\n",
    "input_data = pd.DataFrame([\"Hello, how are you?\"], columns=[\"prompt\"])\n",
    "result = model.predict(input_data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5df38c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160d5aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
